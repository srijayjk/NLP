{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-g74QsbtULq"
      },
      "source": [
        "# **Text generation using Recurrent Neural Network NLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqSD-lQxtFMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a97ecce-4872-4dac-d396-e7214cdd2023"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CZOvykwwX49"
      },
      "source": [
        "import os\n",
        "import datetime \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from urllib.request import urlopen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3opmgBOyJMu"
      },
      "source": [
        "datafile_path = 'https://sherlock-holm.es/stories/plain-text/advs.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnVNn3ZHwksa",
        "outputId": "99b85c60-bfc1-4909-8792-b9d697d36666"
      },
      "source": [
        "data = urlopen(datafile_path).read().decode('utf-8')\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "610871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGyx42cMynQG",
        "outputId": "f7d91290-a366-40a2-8739-5d11756fe6cb"
      },
      "source": [
        "print(data[:1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "                        THE ADVENTURES OF SHERLOCK HOLMES\n",
            "\n",
            "                               Arthur Conan Doyle\n",
            "\n",
            "\n",
            "\n",
            "                                Table of contents\n",
            "\n",
            "               A Scandal in Bohemia\n",
            "               The Red-Headed League\n",
            "               A Case of Identity\n",
            "               The Boscombe Valley Mystery\n",
            "               The Five Orange Pips\n",
            "               The Man with the Twisted Lip\n",
            "               The Adventure of the Blue Carbuncle\n",
            "               The Adventure of the Speckled Band\n",
            "               The Adventure of the Engineer's Thumb\n",
            "               The Adventure of the Noble Bachelor\n",
            "               The Adventure of the Beryl Coronet\n",
            "               The Adventure of the Copper Beeches\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                              A SCANDAL IN BOHEMIA\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                Table of contents\n",
            "                                     Chapter 1\n",
            "                                     Chapter 2\n",
            "                                     Chapter 3\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "          CHAPTER I\n",
            "\n",
            "\n",
            "\n",
            "  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exBW4ib34YVB"
      },
      "source": [
        "text = data[1000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzJ672LTy2EX",
        "outputId": "ac4e10c5-0f4c-4416-a103-a623a7b7b1e8"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "84 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Z5L36h4t2_"
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOPNFhsW5HE9",
        "outputId": "bfe31af2-552d-4da8-8463-49fd3fbfa629"
      },
      "source": [
        "print('{')\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "  print('  {:4s}: {:3d}'.format(repr(char), char2idx[char]))\n",
        "print('....\\n}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  '\\n':   0\n",
            "  ' ' :   1\n",
            "  '!' :   2\n",
            "  '\"' :   3\n",
            "  '&' :   4\n",
            "  \"'\" :   5\n",
            "  '(' :   6\n",
            "  ')' :   7\n",
            "  ',' :   8\n",
            "  '-' :   9\n",
            "  '.' :  10\n",
            "  '/' :  11\n",
            "  '0' :  12\n",
            "  '1' :  13\n",
            "  '2' :  14\n",
            "  '3' :  15\n",
            "  '4' :  16\n",
            "  '5' :  17\n",
            "  '6' :  18\n",
            "  '7' :  19\n",
            "....\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emeNoB9V6DBa",
        "outputId": "a532d469-f07c-4d94-a712-236daa5ccb8f"
      },
      "source": [
        "print('{} ----char-2-int-----{}'.format(repr(text[40:60]), text_as_int[40:60]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'woman. I have seldom' ----char-2-int-----[74 66 64 52 65 10  1 33  1 59 52 73 56  1 70 56 63 55 66 64]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XCRFrtJ6m-M",
        "outputId": "953e579a-1693-41c3-c788-024819fdf093"
      },
      "source": [
        "seq_length = 100\n",
        "exmaples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for i in char_dataset.take(10):\n",
        "  print(idx2char[i.numpy()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            "T\n",
            "o\n",
            " \n",
            "S\n",
            "h\n",
            "e\n",
            "r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPR6lk5s7S2F",
        "outputId": "61b5eb56-7a80-4a5f-c6f0-79aa0e39a97d"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for item in sequences.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))\n",
        "  print(\"-\"*110)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'   To Sherlock Holmes she is always the woman. I have seldom heard him\\n     mention her under any oth'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'er name. In his eyes she eclipses and\\n     predominates the whole of her sex. It was not that he felt'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "' any\\n     emotion akin to love for Irene Adler. All emotions, and that one\\n     particularly, were ab'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'horrent to his cold, precise but admirably\\n     balanced mind. He was, I take it, the most perfect re'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'asoning and\\n     observing machine that the world has seen, but as a lover he would\\n     have placed '\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'himself in a false position. He never spoke of the softer\\n     passions, save with a gibe and a sneer'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "\". They were admirable things\\n     for the observer--excellent for drawing the veil from men's motives\"\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'\\n     and actions. But for the trained reasoner to admit such intrusions\\n     into his own delicate a'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'nd finely adjusted temperament was to\\n     introduce a distracting factor which might throw a doubt u'\n",
            "--------------------------------------------------------------------------------------------------------------\n",
            "'pon all his\\n     mental results. Grit in a sensitive instrument, or a crack in one of\\n     his own hi'\n",
            "--------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsEDCGyUxOfb"
      },
      "source": [
        "Split the input and ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyQV1eTyvMML"
      },
      "source": [
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EarNsQ9-xUF1"
      },
      "source": [
        "Visualize Input and Ground Truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pd0BkNbvMPk",
        "outputId": "8b08a0a0-ae18-437c-b27b-14edc002f74d"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print('Input data:', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input data: '   To Sherlock Holmes she is always the woman. I have seldom heard him\\n     mention her under any ot'\n",
            "Target data: '  To Sherlock Holmes she is always the woman. I have seldom heard him\\n     mention her under any oth'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wFNzIz3xG_z"
      },
      "source": [
        "Expection from Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3Ws803zvMV_",
        "outputId": "ea0b1c46-e17e-44c6-b716-12a452f527dc"
      },
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "  print(\"step {:4d}\".format(i))\n",
        "  print(\" input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "  print(\" expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "step    0\n",
            " input: 1 (' ')\n",
            " expected output: 1 (' ')\n",
            "step    1\n",
            " input: 1 (' ')\n",
            " expected output: 1 (' ')\n",
            "step    2\n",
            " input: 1 (' ')\n",
            " expected output: 44 ('T')\n",
            "step    3\n",
            " input: 44 ('T')\n",
            " expected output: 66 ('o')\n",
            "step    4\n",
            " input: 66 ('o')\n",
            " expected output: 1 (' ')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ielG4bxa74"
      },
      "source": [
        "Prepare Training Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B63pSoJvMcb"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TvotclHvMhe",
        "outputId": "e63aa3e5-9584-4d14-b743-562d0806738b"
      },
      "source": [
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(\"Dataset Shape={}\".format(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Shape=<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJTjQE4x821"
      },
      "source": [
        "Prepare Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ekm9aBqvMlV"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "  tf.keras.layers.GRU(rnn_units, return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'),\n",
        "  tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CZ67bJ_y0Sj"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "embedding_dim = 512\n",
        "\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rfqE8IQzCAG",
        "outputId": "66ba0625-079f-4a26-9fc7-ae33f60cea6d"
      },
      "source": [
        "model = build_model(vocab_size=len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (64, None, 512)           43008     \n",
            "_________________________________________________________________\n",
            "gru_5 (GRU)                  (64, None, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (64, None, 84)            86100     \n",
            "=================================================================\n",
            "Total params: 4,853,844\n",
            "Trainable params: 4,853,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOXngPWXtSuy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DskGaPWEzXFV"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5BKhGgkzXac"
      },
      "source": [
        "checkpoint_dir = r'data/training_chechpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUzqsCxmzXfe"
      },
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tesnsorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JCnHoZH0wFO",
        "outputId": "45f92e6d-6de0-4ce2-e4fb-5b5b8c127eb6"
      },
      "source": [
        "EPOCHS = 64\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback, tesnsorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "94/94 [==============================] - 6s 67ms/step - loss: 2.8087\n",
            "Epoch 2/64\n",
            "94/94 [==============================] - 6s 65ms/step - loss: 1.9869\n",
            "Epoch 3/64\n",
            "94/94 [==============================] - 6s 65ms/step - loss: 1.7517\n",
            "Epoch 4/64\n",
            "94/94 [==============================] - 6s 65ms/step - loss: 1.5939\n",
            "Epoch 5/64\n",
            "94/94 [==============================] - 6s 66ms/step - loss: 1.4692\n",
            "Epoch 6/64\n",
            "94/94 [==============================] - 6s 66ms/step - loss: 1.3762\n",
            "Epoch 7/64\n",
            "94/94 [==============================] - 6s 67ms/step - loss: 1.3061\n",
            "Epoch 8/64\n",
            "94/94 [==============================] - 6s 67ms/step - loss: 1.2498\n",
            "Epoch 9/64\n",
            "94/94 [==============================] - 6s 67ms/step - loss: 1.2039\n",
            "Epoch 10/64\n",
            "94/94 [==============================] - 6s 69ms/step - loss: 1.1643\n",
            "Epoch 11/64\n",
            "94/94 [==============================] - 6s 68ms/step - loss: 1.1278\n",
            "Epoch 12/64\n",
            "94/94 [==============================] - 6s 68ms/step - loss: 1.0918\n",
            "Epoch 13/64\n",
            "94/94 [==============================] - 6s 69ms/step - loss: 1.0601\n",
            "Epoch 14/64\n",
            "94/94 [==============================] - 7s 69ms/step - loss: 1.0254\n",
            "Epoch 15/64\n",
            "94/94 [==============================] - 7s 70ms/step - loss: 0.9923\n",
            "Epoch 16/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.9606\n",
            "Epoch 17/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.9264\n",
            "Epoch 18/64\n",
            "94/94 [==============================] - 7s 72ms/step - loss: 0.8907\n",
            "Epoch 19/64\n",
            "94/94 [==============================] - 7s 72ms/step - loss: 0.8551\n",
            "Epoch 20/64\n",
            "94/94 [==============================] - 7s 73ms/step - loss: 0.8195\n",
            "Epoch 21/64\n",
            "94/94 [==============================] - 7s 72ms/step - loss: 0.7839\n",
            "Epoch 22/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.7484\n",
            "Epoch 23/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.7118\n",
            "Epoch 24/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.6788\n",
            "Epoch 25/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.6444\n",
            "Epoch 26/64\n",
            "94/94 [==============================] - 7s 70ms/step - loss: 0.6136\n",
            "Epoch 27/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.5831\n",
            "Epoch 28/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.5556\n",
            "Epoch 29/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.5296\n",
            "Epoch 30/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.5038\n",
            "Epoch 31/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4861\n",
            "Epoch 32/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4683\n",
            "Epoch 33/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4511\n",
            "Epoch 34/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4362\n",
            "Epoch 35/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4240\n",
            "Epoch 36/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4140\n",
            "Epoch 37/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.4017\n",
            "Epoch 38/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3956\n",
            "Epoch 39/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3891\n",
            "Epoch 40/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3820\n",
            "Epoch 41/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3769\n",
            "Epoch 42/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3696\n",
            "Epoch 43/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3656\n",
            "Epoch 44/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3648\n",
            "Epoch 45/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3599\n",
            "Epoch 46/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3562\n",
            "Epoch 47/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3534\n",
            "Epoch 48/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3499\n",
            "Epoch 49/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3483\n",
            "Epoch 50/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3488\n",
            "Epoch 51/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3472\n",
            "Epoch 52/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3440\n",
            "Epoch 53/64\n",
            "94/94 [==============================] - 7s 72ms/step - loss: 0.3421\n",
            "Epoch 54/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3414\n",
            "Epoch 55/64\n",
            "94/94 [==============================] - 7s 70ms/step - loss: 0.3413\n",
            "Epoch 56/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3406\n",
            "Epoch 57/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3380\n",
            "Epoch 58/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3377\n",
            "Epoch 59/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3372\n",
            "Epoch 60/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3359\n",
            "Epoch 61/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3345\n",
            "Epoch 62/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3377\n",
            "Epoch 63/64\n",
            "94/94 [==============================] - 7s 70ms/step - loss: 0.3357\n",
            "Epoch 64/64\n",
            "94/94 [==============================] - 7s 71ms/step - loss: 0.3339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Fnkafjw42pJQ",
        "outputId": "5bd0f42a-30ed-4571-ccce-c16e8283efbc"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data/training_chechpoints/ckpt_64'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWD7YRq80xwY",
        "outputId": "b75418ed-6ff5-49b1-cf3f-52a0d96165b8"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghtm0XZy0x1n",
        "outputId": "711b38ce-0d67-41db-f737-c874565309e6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (1, None, 512)            43008     \n",
            "_________________________________________________________________\n",
            "gru_6 (GRU)                  (1, None, 1024)           4724736   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (1, None, 84)             86100     \n",
            "=================================================================\n",
            "Total params: 4,853,844\n",
            "Trainable params: 4,853,844\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW62B51n4Qi1"
      },
      "source": [
        "context_string: Input string which acts as context for the model\n",
        "num_generator: Number of Characters genearted\n",
        "temperature: prameter to control rendomness of the outputs\n",
        "\n",
        "return context string and test generated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofXG5K_N3LJe"
      },
      "source": [
        "def generate_text(model, context_string, num_generate=1000, temperature=1.0):\n",
        "  input_eval = [char2idx[s] for s in context_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "  text_generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (context_string + ''.join(text_generated))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "davQ7A5q3LOz",
        "outputId": "7ae1b7ec-553d-42ce-83f5-ba08e346069a"
      },
      "source": [
        "print(generate_text(model, context_string=u\"Watson you are\", num_generate=100, temperature=0.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Watson you are an hour the miserable weather and the\n",
            "     moment the room and saw the door, \"yet there not been in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiGg4MI-3LUf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c5OEdDZ3LXS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}